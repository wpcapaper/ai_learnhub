import os
import sys
import json
import asyncio
import re
import requests
from pathlib import Path
from typing import List, Dict, Any
from dotenv import load_dotenv
from openai import AsyncOpenAI

# å°è¯•å¯¼å…¥ BeautifulSoup
try:
    from bs4 import BeautifulSoup
    HAS_BS4 = True
except ImportError:
    HAS_BS4 = False
    print("Warning: beautifulsoup4 not found. HTML parsing will be limited.")

# åŠ è½½ç¯å¢ƒå˜é‡
# å‡è®¾è„šæœ¬ä½äº scripts/ ç›®å½•ï¼Œ.env ä½äº src/backend/ ç›®å½•
BASE_DIR = Path(__file__).resolve().parent.parent
BACKEND_DIR = BASE_DIR / 'src' / 'backend'
ENV_PATH = BACKEND_DIR / '.env'

if ENV_PATH.exists():
    load_dotenv(ENV_PATH)
    print(f"Loaded environment from {ENV_PATH}")
else:
    print(f"Warning: .env file not found at {ENV_PATH}")

# é…ç½® OpenAI å®¢æˆ·ç«¯
API_KEY = os.getenv("DEEPSEEK_API_KEY")
BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
MODEL = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")

if not API_KEY:
    print("Error: DEEPSEEK_API_KEY environment variable not set.")
    sys.exit(1)

client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)

def clean_html(html_content: str) -> str:
    """æ¸…ç† HTML å†…å®¹ï¼Œæå–ä¸»è¦æ–‡æœ¬"""
    if not HAS_BS4:
        # ç®€å•çš„æ­£åˆ™æ¸…ç†
        text = re.sub(r'<[^>]+>', '', html_content)
        return "\n".join([line.strip() for line in text.splitlines() if line.strip()])
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # ç§»é™¤è„šæœ¬ã€æ ·å¼ã€å¯¼èˆªã€é¡µè„šã€ä¾§è¾¹æ ã€å¼•ç”¨ã€ç¼–è¾‘é“¾æ¥ç­‰æ— å…³å†…å®¹
    for element in soup(["script", "style", "nav", "footer", "header", "aside", "sup", "noscript", "iframe"]):
        element.decompose()
        
    # é’ˆå¯¹ç»´åŸºç™¾ç§‘ç­‰ç½‘ç«™çš„ç‰¹æ®Šå¤„ç†ï¼šç§»é™¤ "mw-editsection" (ç¼–è¾‘æŒ‰é’®), "reflist" (å‚è€ƒæ–‡çŒ®), "infobox" (ä¿¡æ¯æ¡†ï¼Œå¯é€‰ä¿ç•™)
    for class_name in ["mw-editsection", "reflist", "reference", "site-notice", "mw-jump-link"]:
        for element in soup.find_all(class_=class_name):
            element.decompose()

    # æå–ä¸»è¦å†…å®¹åŒºåŸŸ (é’ˆå¯¹ç»´åŸºç™¾ç§‘æ˜¯ 'mw-content-text'ï¼Œå…¶ä»–ç½‘ç«™é€šå¸¸æ˜¯ 'main', 'article', 'content')
    main_content = soup.find(id="mw-content-text") or soup.find("main") or soup.find("article") or soup.body
    
    if not main_content:
        main_content = soup.body

    # è·å–æ–‡æœ¬ï¼Œä¿ç•™ä¸€å®šçš„ç»“æ„
    # æˆ‘ä»¬åªæå–ç‰¹å®šçš„æ ‡ç­¾æ–‡æœ¬ï¼Œä»¥ä¿æŒå†…å®¹çš„çº¯å‡€åº¦
    content_lines = []
    for element in main_content.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'ul', 'ol', 'pre', 'code', 'table']):
        text = element.get_text().strip()
        if text:
            # ç®€å•çš„æ ¼å¼ä¿ç•™
            if element.name.startswith('h'):
                content_lines.append(f"\n# {text}\n")
            elif element.name == 'ul' or element.name == 'ol':
                # åˆ—è¡¨é¡¹å•ç‹¬å¤„ç†ä¼šæ›´ç²¾ç»†ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
                content_lines.append(f"{text}\n")
            else:
                content_lines.append(f"{text}\n")
    
    return "\n".join(content_lines)

async def fetch_url_content(url: str) -> str:
    """è·å– URL å†…å®¹"""
    print(f"Fetching content from: {url}")
    # æ·»åŠ  User-Agent ä¼ªè£…æˆæµè§ˆå™¨ï¼Œé¿å…è¢«ç»´åŸºç™¾ç§‘ç­‰ç½‘ç«™æ‹¦æˆª (403 Forbidden)
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        return clean_html(response.text)
    except Exception as e:
        print(f"Error fetching URL: {e}")
        return None

async def generate_course_outline(content: str) -> Dict[str, Any]:
    """Phase 1: Generate course outline (metadata + chapter list) without full content"""
    print("Phase 1: Generating course outline...")

    system_prompt = """
    You are an expert Course Curator. Your task is to analyze the provided text and plan a structured learning course.
    
    IMPORTANT: Output MUST be in SIMPLIFIED CHINESE (ç®€ä½“ä¸­æ–‡).
    
    Output a strictly valid JSON object with this structure:
    {
        "code": "unique_slug_code",
        "title": "Course Title (Chinese)",
        "description": "Course Description (Chinese)",
        "cover_image": "https://placehold.co/600x400?text=Course+Cover", 
        "chapters": [
            {
                "title": "Chapter Title (Chinese)",
                "file": "01_chapter_slug.md",
                "summary": "Brief description of what this chapter covers (used for context)"
            }
        ]
    }
    
    Rules:
    1. 'code' should be lowercase, using underscores (e.g., 'python_basics').
    2. Divide content into 5-10 logical chapters for depth.
    3. JSON only, no markdown formatting.
    """

    try:
        response = await client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Plan a course based on this content (first 20k chars):\n\n{content[:20000]}..."}
            ],
            temperature=0.3,
            max_tokens=2000,
            response_format={"type": "json_object"}
        )
        
        result = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(result)
    except Exception as e:
        print(f"Error generating outline: {e}")
        return None

async def generate_chapter_content(chapter_title: str, chapter_summary: str, full_content: str) -> str:
    """Phase 2: Generate detailed content for a specific chapter"""
    print(f"Phase 2: Generating content for chapter '{chapter_title}'...")
    
    system_prompt = f"""
    You are an expert Course Curator writing a specific chapter for a course.
    
    Target Chapter: "{chapter_title}"
    Chapter Goal: {chapter_summary}
    
    Task: Write a DETAILED, COMPREHENSIVE educational tutorial for this chapter based on the Source Content.
    
    Requirements:
    1. Language: SIMPLIFIED CHINESE (ç®€ä½“ä¸­æ–‡).
    2. Format: Standard Markdown.
    3. Structure: Use H2 (##) for main sections, bullet points, and code blocks where relevant.
    4. Depth: Do not summarize. Explain concepts fully with examples from the source.
    5. Length: Aim for 1000+ words if source material supports it.
    """

    try:
        response = await client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Source Content:\n\n{full_content[:40000]}"} # Increase context limit
            ],
            temperature=0.4,
            max_tokens=4000
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error generating chapter content: {e}")
        return f"# {chapter_title}\n\n(Content generation failed. Please check logs.)"


def save_course(course_data: Dict[str, Any], output_root: Path):
    """ä¿å­˜è¯¾ç¨‹æ–‡ä»¶"""
    course_slug = course_data.get("code")
    if not course_slug:
        print("Error: No course code found in data.")
        return

    course_dir = output_root / course_slug
    course_dir.mkdir(parents=True, exist_ok=True)
    print(f"Created course directory: {course_dir}")

    # 1. ä¿å­˜ course.json (ä¸åŒ…å« content å­—æ®µ)
    meta_data = {k: v for k, v in course_data.items() if k != "chapters"}
    
    # å¤„ç†ç« èŠ‚å…ƒæ•°æ®
    chapters_meta = []
    chapters_data = course_data.get("chapters", [])
    
    for chapter in chapters_data:
        chapters_meta.append({
            "title": chapter.get("title"),
            "file": chapter.get("file"),
            "sort_order": chapter.get("sort_order")
        })
        
        # 2. ä¿å­˜ç« èŠ‚ Markdown æ–‡ä»¶
        file_name = chapter.get("file")
        content = chapter.get("content", "")
        
        # ç¡®ä¿æ–‡ä»¶åä»¥ .md ç»“å°¾
        if not file_name.endswith('.md'):
            file_name += '.md'
            
        file_path = course_dir / file_name
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"Saved chapter: {file_name}")

    meta_data["chapters"] = chapters_meta
    
    with open(course_dir / "course.json", 'w', encoding='utf-8') as f:
        json.dump(meta_data, f, indent=2, ensure_ascii=False)
    print("Saved course.json")

    return course_dir

async def main():
    if len(sys.argv) < 2:
        print("Usage: python generate_course_from_url.py <URL or Text File Path>")
        print("Example: python generate_course_from_url.py https://en.wikipedia.org/wiki/Python_(programming_language)")
        sys.exit(1)
    
    input_source = sys.argv[1]
    content = ""
    
    # åˆ¤æ–­æ˜¯ URL è¿˜æ˜¯æ–‡ä»¶
    if input_source.startswith(('http://', 'https://')):
        content = await fetch_url_content(input_source)
    elif Path(input_source).exists():
        file_path = Path(input_source)
        print(f"Reading file: {file_path}")
        
        # é’ˆå¯¹ .ipynb æ–‡ä»¶çš„ç‰¹æ®Šå¤„ç†
        if file_path.suffix.lower() == '.ipynb':
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    notebook = json.load(f)
                    
                lines = []
                for cell in notebook.get('cells', []):
                    cell_type = cell.get('cell_type')
                    source = cell.get('source', [])
                    if isinstance(source, list):
                        source_text = ''.join(source)
                    else:
                        source_text = str(source)
                        
                    if cell_type == 'markdown':
                        lines.append(source_text)
                    elif cell_type == 'code':
                        lines.append(f"```python\n{source_text}\n```")
                
                content = "\n\n".join(lines)
                print(f"Successfully parsed notebook. Extracted {len(content)} chars.")
            except Exception as e:
                print(f"Error parsing .ipynb file: {e}")
                sys.exit(1)
        else:
            # æ™®é€šæ–‡æœ¬æ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
    else:
        print("Error: Input is neither a valid URL nor an existing file.")
        sys.exit(1)
        
    if not content:
        print("Failed to get content. Exiting.")
        sys.exit(1)
        
    course_outline = await generate_course_outline(content)
    
    if course_outline:
        # Phase 2: Iterate and fill content
        final_chapters = []
        chapters = course_outline.get("chapters", [])
        total_chapters = len(chapters)
        
        print(f"\nCourse Outline Generated: '{course_outline.get('title')}' with {total_chapters} chapters.")
        print("Starting detailed content generation (this may take a while)...\n")
        
        for i, chapter in enumerate(chapters, 1):
            title = chapter.get("title")
            summary = chapter.get("summary", "")
            print(f"[{i}/{total_chapters}] Generating: {title}...")
            
            # Generate detailed content
            detailed_content = await generate_chapter_content(title, summary, content)
            
            # Update chapter object
            chapter["content"] = detailed_content
            chapter["sort_order"] = i # Ensure sort order
            final_chapters.append(chapter)
            
        course_outline["chapters"] = final_chapters
        
        # è¾“å‡ºç›®å½•ï¼šscripts/../learning_courses
        # ç”¨æˆ·ç‰¹åˆ«è¦æ±‚è¾“å‡ºåˆ° learning_courses/ ç›®å½•
        output_root = BASE_DIR / 'learning_courses'
        
        # å¦‚æœ learning_courses ä¸å­˜åœ¨ï¼Œå°è¯• courses (ä¸ºäº†å…¼å®¹æ€§)ï¼Œæˆ–è€…ç›´æ¥åˆ›å»º learning_courses
        if not output_root.exists():
            output_root.mkdir(exist_ok=True)
            
        saved_dir = save_course(course_outline, output_root)
        
        print("\n" + "="*50)
        print(f"âœ… Course generation complete!")
        print(f"ğŸ“ Course Location: {saved_dir}")
        print("="*50)
        print("\nğŸ‘‡ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. è¯·æ£€æŸ¥ä¸Šè¿°æ–‡ä»¶å¤¹ä¸­ç”Ÿæˆçš„ Markdown æ–‡ä»¶ã€‚")
        print("2. ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å°†è¯¾ç¨‹å¯¼å…¥æ•°æ®åº“ï¼š")
        print(f'   python scripts/import_learning_courses.py "{output_root}"')
        print("\n   (æ³¨æ„ï¼šæ­¤å‘½ä»¤å°†æ‰«æå¹¶å¯¼å…¥è¯¥æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰è¯¾ç¨‹)")
        
    else:
        print("Failed to generate course structure.")

if __name__ == "__main__":
    asyncio.run(main())